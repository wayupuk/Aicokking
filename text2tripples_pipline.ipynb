{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torchaudio\n",
    "!pip install torch\n",
    "!pip install -q pydub\n",
    "!pip3 install -q -U bitsandbytes==0.42.0\n",
    "!pip3 install -q -U peft==0.8.2\n",
    "!pip3 install -q -U trl\n",
    "!pip3 install -q -U accelerate==0.27.1\n",
    "!pip3 install -q -U datasets==2.17.0\n",
    "!pip3 install -q -U transformers==4.38.0\n",
    "USE_ONNX = False # change this to True if you want to test onnx model\n",
    "if USE_ONNX:\n",
    "    !pip install -q onnxruntime\n",
    "!pip install -q huggingsound\n",
    "#@title Install and Import Dependencies\n",
    "\n",
    "# this assumes that you have a relevant version of PyTorch installed\n",
    "SAMPLING_RATE = 16000\n",
    "import torch\n",
    "torch.set_num_threads(1)\n",
    "from IPython.display import Audio\n",
    "from pprint import pprint\n",
    "# download example\n",
    "# torch.hub.download_url_to_file('https://models.silero.ai/vad_models/en.wav', 'en_example.wav')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as n\n",
    "import transformers\n",
    "from transformers import (AutoModelForCausalLM,\n",
    "                          AutoTokenizer,\n",
    "                          BitsAndBytesConfig,\n",
    "                          TrainingArguments,\n",
    "                          pipeline,\n",
    "                          logging)\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, PeftConfig\n",
    "import bitsandbytes as bnb\n",
    "from trl import SFTTrainer\n",
    "from tqdm.notebook import tqdm\n",
    "# from sklearn.metrics import (accuracy_score,\n",
    "#                              classification_report,\n",
    "#                              confusion_matrix)\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "\n",
    "model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad',\n",
    "                              model='silero_vad',\n",
    "                              force_reload=True,\n",
    "                              onnx=USE_ONNX)\n",
    "\n",
    "(get_speech_timestamps,\n",
    " save_audio,\n",
    " read_audio,\n",
    " VADIterator,\n",
    " collect_chunks) = utils\n",
    "\n",
    "model_name = \" qwen2-7b-instruct\"\n",
    "\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,\n",
    "#     bnb_4bit_use_double_quant=False,\n",
    "#     bnb_4bit_quant_type=\"nf4\",\n",
    "#     bnb_4bit_compute_dtype=compute_dtype,\n",
    "# )\n",
    "\n",
    "model_txt = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    # quantization_config=bnb_config,\n",
    "    local_files_only = True\n",
    ")\n",
    "\n",
    "model_txt.config.use_cache = False\n",
    "model_txt.config.pretraining_tp = 1\n",
    "\n",
    "tokenizer_txt = AutoTokenizer.from_pretrained(model_name)\n",
    "## using VADIterator class\n",
    "# ! ffmpeg -i /content/voice_11318.mp4 -acodec pcm_s16le -ar 16000 -y output.wav\n",
    "\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "from huggingsound import SpeechRecognitionModel\n",
    "import torch\n",
    "import transformers\n",
    "vad_iterator = VADIterator(model)\n",
    "timestamps = []\n",
    "wav = read_audio(f'/content/output.wav', sampling_rate=SAMPLING_RATE)\n",
    "\n",
    "window_size_samples = 1536 # number of samples in a single audio chunk\n",
    "for i in range(0, len(wav), window_size_samples):\n",
    "    chunk = wav[i: i+ window_size_samples]\n",
    "    if len(chunk) < window_size_samples:\n",
    "      break\n",
    "    speech_dict = vad_iterator(chunk, return_seconds=True)\n",
    "    if speech_dict:\n",
    "        timestamps.append(speech_dict)\n",
    "        # print(speech_dict, end=' ')\n",
    "vad_iterator.reset_states() # reset model states after each audio\n",
    "\n",
    "\n",
    "def cut_wav_chunks(input_file, timestamps):\n",
    "    # Load the audio file\n",
    "    audio = AudioSegment.from_wav(input_file)\n",
    "\n",
    "    chunks = []\n",
    "    for i in range(0, len(timestamps), 2):\n",
    "        start = timestamps[i].get('start', 0) * 1000  # Convert to milliseconds\n",
    "        end = timestamps[i+1].get('end', len(audio)) * 1000  # Convert to milliseconds\n",
    "        chunk = audio[start:end]\n",
    "        chunks.append(chunk)\n",
    "\n",
    "    return chunks\n",
    "# Path to your input WAV file\n",
    "input_file = \"/content/output.wav\"\n",
    "output_dir = \"/content/sound\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "# Cut the chunks\n",
    "chunks = cut_wav_chunks(input_file, timestamps)\n",
    "\n",
    "# Save the chunks\n",
    "for i, chunk in enumerate(chunks):\n",
    "\n",
    "    chunk.export(f\"/content/sound/chunk_{i+1}.wav\", format=\"wav\")\n",
    "\n",
    "# Function to extract the numeric value from the filename\n",
    "\n",
    "\n",
    "audio_path = []\n",
    "for a in os.listdir('/content/sound'):\n",
    "  full_path = os.path.join('/content/sound', a)\n",
    "  if os.path.isfile(full_path):\n",
    "    audio_path.append(full_path)\n",
    "\n",
    "\n",
    "def extract_number(file_path):\n",
    "    filename = file_path.split('/')[-1]\n",
    "    number = int(filename.split('_')[1].split('.')[0])\n",
    "    return number\n",
    "\n",
    "sorted_file_paths = sorted(audio_path, key=extract_number)\n",
    "\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "model = SpeechRecognitionModel(\"airesearch/wav2vec2-large-xlsr-53-th\", device = device)\n",
    "\n",
    "transcriptions = model.transcribe(sorted_file_paths)\n",
    "chunk_word = []\n",
    "full_transcript =''\n",
    "for item in transcriptions:\n",
    "    chunk_word.append(item['transcription'].replace(\" \",\"\"))\n",
    "    print(\"//\",item['transcription'].replace(\" \",\"\"),\"//\")\n",
    "    full_transcript += ''.join(item['transcription'].replace(\" \",\"\"))\n",
    "\n",
    "\n",
    "def extract_and_combine(text):\n",
    "    \"\"\"\n",
    "    Extract JSON strings between |<start>| and |<end>| markers and combine them into a single JSON array.\n",
    "\n",
    "    :param text: The input text containing the JSON strings\n",
    "    :return: A combined JSON string\n",
    "    \"\"\"\n",
    "    trl_ar = []\n",
    "    # Regular expression to find JSON strings between |<start>| and |<end>|\n",
    "    pattern = r'\\|<start>\\|(.*?)\\|<end>\\|'\n",
    "    matches = re.findall(pattern, text)\n",
    "    [trl_ar.append(matche) for matche in matches]\n",
    "    # # Parse the matched JSON strings and combine them into a list\n",
    "    # json_objects = [json.loads(match) for match in matches]\n",
    "    \n",
    "    # # Convert the list of JSON objects back to a JSON string\n",
    "    # combined_json_string = json.dumps(json_objects, ensure_ascii=False)\n",
    "    \n",
    "    return trl_ar\n",
    "\n",
    "def cutting(prompt):\n",
    "    messagee = prompt.split(\" \")\n",
    "    return messagee\n",
    "\n",
    "\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\", model=model_txt,\n",
    "    tokenizer=tokenizer,\n",
    "    model_kwargs={\"torch_dtype\": torch.float16},\n",
    "    trust_remote_code = True,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "if full_transcript:\n",
    "    prompt = full_transcript\n",
    "else:\n",
    "    prompt = \"\"\"มีการรายงานข่าวเกี่ยวกับเหตุการณ์ที่เจ้าหน้าที่ตำรวจเข้าตรวจสอบอาจารย์หญิงคนหนึ่งที่เป็นผู้นำทางจิตวิญญาณของชาวบ้านในสำนักสุขาวดี จังหวัดอุดรธานี โดยตอนแรกเจ้าหน้าที่ไม่ทราบชื่อจริงของเธอ จนกระทั่งพบว่าเธอเคยเปลี่ยนชื่อมาหลายครั้ง และมีหมายจับเกี่ยวกับการทุจริตและการนำเข้าข้อมูลอันเป็นเท็จสู่ระบบคอมพิวเตอร์เมื่อเจ้าหน้าที่ควบคุมตัวอาจารย์หญิงคนนี้ เธอกล่าวว่าไม่ได้รู้สึกเครียดและบอกว่าร่างของเธอถูกครอบครองโดยวิญญาณอื่น จากการตรวจสอบพบว่าเธอเคยเป็นนักธุรกิจและซีอีโอของบริษัทหนึ่ง ซึ่งหลังจากมีคดีความเกี่ยวกับการเงิน เธอก็หันมาเป็นผู้นำทางจิตวิญญาณในห้องขัง เธอนั่งสมาธิและอ้างว่าได้ช่วยปลดปล่อยดวงวิญญาณนักรบในอดีตหลายหมื่นดวง อย่างไรก็ตาม เจ้าหน้าที่ตำรวจยืนยันว่าเธอมีคดีความที่ยังต้องสอบสวนและมีการควบคุมตัวต่อไป ซึ่งเธอได้รับการประกันตัวในที่สุดเหตุการณ์นี้ทำให้หลายคนสงสัยเกี่ยวกับความเชื่อและพฤติกรรมของเธอ รวมถึงการดำเนินการของเจ้าหน้าที่ในการตรวจสอบคดีความของเธอที่เกี่ยวข้องกับการทุจริตในอดีต\"\"\"\n",
    "\n",
    "messagee = cutting(prompt)\n",
    "persona_llm = \"\"\"you are Narin Phon an experrt in correcting sentence\n",
    "Skills:\n",
    "Text Correction: Expertise in identifying and correcting grammatical, syntactical, and contextual errors in Thai text.\n",
    "Data Annotation: Experience in creating and managing annotated datasets for training language models.\"\"\"\n",
    "massive = []\n",
    "for i in messagee:\n",
    "    txt_messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"\"\"{persona_llm}.\n",
    "        you must answer like this [\n",
    "            input =  พระบรมมทาตสวีตั้งอยู่บนถนนเพชรเกษมที่ตั้งท่ามกลางทะเลอันดาหมั่นของจังหวัดสงขลานมีตำนานเกี่ยวกับอารังกาศักดิ์สิทธิิ์ซึ่งรวมอยู่ในภูเหารับล่อใกล้เคียงขับ\n",
    "            output = |<start>|พระบรมธาตุสวีตั้งอยู่บนถนนเพชรเกษมที่ตั้งท่ามกลางทะเลอันดามันของจังหวัดสงขลา มีตำนานเกี่ยวกับลังกาศักดิ์สิทธิ์ซึ่งร่วมอยู่ในภูเขารับร่อใกล้เคียงครับ|<end>|\n",
    "            ]\n",
    "            if output has more than one use \",\" between them \n",
    "        \"\"\"},\n",
    "        {\"role\": \"user\", \"content\":f\"{i}\"}\n",
    "    ]\n",
    "    massive.append(txt_messages)\n",
    "\n",
    "outputs = []\n",
    "for j in tqdm(range(len(messagee))):\n",
    "    i = messagee[j]\n",
    "    txt_messages = massive[j]\n",
    "    out = pipeline(\n",
    "        txt_messages,\n",
    "        max_new_tokens=128,\n",
    "        temperature=0.01,\n",
    "        early_stopping=True,\n",
    "        num_beams=1,top_k=3, \n",
    "        eos_token_id=model.config.eos_token_id\n",
    "    )\n",
    "    # print(out)\n",
    "    outputs.append(out)\n",
    "\n",
    "\n",
    "cleaned = []\n",
    "for i in outputs:\n",
    "    output_text = extract_and_combine(i[0][\"generated_text\"][2][\"content\"])\n",
    "    cleaned.append(output_text[0])\n",
    "# df = to_dfa(cleaned)\n",
    "# df\n",
    "correct_txt = \" \".join(cleaned)\n",
    "correct_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Install and Import Dependencies\n",
    "\n",
    "# this assumes that you have a relevant version of PyTorch installed\n",
    "SAMPLING_RATE = 16000\n",
    "import torch\n",
    "torch.set_num_threads(1)\n",
    "from IPython.display import Audio\n",
    "from pprint import pprint\n",
    "# download example\n",
    "# torch.hub.download_url_to_file('https://models.silero.ai/vad_models/en.wav', 'en_example.wav')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import transformers\n",
    "from transformers import (AutoModelForCausalLM,\n",
    "                          AutoTokenizer,\n",
    "                          BitsAndBytesConfig,\n",
    "                          TrainingArguments,\n",
    "                          pipeline,\n",
    "                          logging)\n",
    "from datasets import Dataset\n",
    "from peft import LoraConfig, PeftConfig\n",
    "import bitsandbytes as bnb\n",
    "from trl import SFTTrainer\n",
    "from tqdm.notebook import tqdm\n",
    "# from sklearn.metrics import (accuracy_score,\n",
    "#                              classification_report,\n",
    "#                              confusion_matrix)\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad',\n",
    "                              model='silero_vad',\n",
    "                              force_reload=True,\n",
    "                              onnx=USE_ONNX)\n",
    "\n",
    "(get_speech_timestamps,\n",
    " save_audio,\n",
    " read_audio,\n",
    " VADIterator,\n",
    " collect_chunks) = utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## using VADIterator class\n",
    "# ! ffmpeg -i /content/voice_11318.mp4 -acodec pcm_s16le -ar 16000 -y output.wav\n",
    "\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "\n",
    "vad_iterator = VADIterator(model)\n",
    "timestamps = []\n",
    "wav = read_audio(f'/content/output.wav', sampling_rate=SAMPLING_RATE)\n",
    "\n",
    "window_size_samples = 1536 # number of samples in a single audio chunk\n",
    "for i in range(0, len(wav), window_size_samples):\n",
    "    chunk = wav[i: i+ window_size_samples]\n",
    "    if len(chunk) < window_size_samples:\n",
    "      break\n",
    "    speech_dict = vad_iterator(chunk, return_seconds=True)\n",
    "    if speech_dict:\n",
    "        timestamps.append(speech_dict)\n",
    "        # print(speech_dict, end=' ')\n",
    "vad_iterator.reset_states() # reset model states after each audio\n",
    "\n",
    "\n",
    "def cut_wav_chunks(input_file, timestamps):\n",
    "    # Load the audio file\n",
    "    audio = AudioSegment.from_wav(input_file)\n",
    "\n",
    "    chunks = []\n",
    "    for i in range(0, len(timestamps), 2):\n",
    "        start = timestamps[i].get('start', 0) * 1000  # Convert to milliseconds\n",
    "        end = timestamps[i+1].get('end', len(audio)) * 1000  # Convert to milliseconds\n",
    "        chunk = audio[start:end]\n",
    "        chunks.append(chunk)\n",
    "\n",
    "    return chunks\n",
    "# Path to your input WAV file\n",
    "input_file = \"/content/output.wav\"\n",
    "output_dir = \"/content/sound\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "# Cut the chunks\n",
    "chunks = cut_wav_chunks(input_file, timestamps)\n",
    "\n",
    "# Save the chunks\n",
    "for i, chunk in enumerate(chunks):\n",
    "\n",
    "    chunk.export(f\"/content/sound/chunk_{i+1}.wav\", format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the numeric value from the filename\n",
    "\n",
    "\n",
    "audio_path = []\n",
    "for a in os.listdir('/content/sound'):\n",
    "  full_path = os.path.join('/content/sound', a)\n",
    "  if os.path.isfile(full_path):\n",
    "    audio_path.append(full_path)\n",
    "\n",
    "\n",
    "def extract_number(file_path):\n",
    "    filename = file_path.split('/')[-1]\n",
    "    number = int(filename.split('_')[1].split('.')[0])\n",
    "    return number\n",
    "\n",
    "sorted_file_paths = sorted(audio_path, key=extract_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingsound import SpeechRecognitionModel\n",
    "import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "model = SpeechRecognitionModel(\"airesearch/wav2vec2-large-xlsr-53-th\", device = device)\n",
    "\n",
    "transcriptions = model.transcribe(sorted_file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "chunk_word = []\n",
    "full_transcript =''\n",
    "for item in transcriptions:\n",
    "    chunk_word.append(item['transcription'].replace(\" \",\"\"))\n",
    "    print(\"//\",item['transcription'].replace(\" \",\"\"),\"//\")\n",
    "    full_transcript += ''.join(item['transcription'].replace(\" \",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-22T02:20:12.793330Z",
     "iopub.status.busy": "2024-06-22T02:20:12.792737Z",
     "iopub.status.idle": "2024-06-22T02:21:51.166213Z",
     "shell.execute_reply": "2024-06-22T02:21:51.165008Z",
     "shell.execute_reply.started": "2024-06-22T02:20:12.793296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cudf 24.4.1 requires cubinlinker, which is not installed.\n",
      "cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "cudf 24.4.1 requires ptxcompiler, which is not installed.\n",
      "cuml 24.4.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "dask-cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "cudf 24.4.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\n",
      "distributed 2024.1.1 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\n",
      "gcsfs 2024.3.1 requires fsspec==2024.3.1, but you have fsspec 2023.10.0 which is incompatible.\n",
      "rapids-dask-dependency 24.4.1a0 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\n",
      "rapids-dask-dependency 24.4.1a0 requires dask-expr==0.4.0, but you have dask-expr 1.1.2 which is incompatible.\n",
      "s3fs 2024.3.1 requires fsspec==2024.3.1, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efeab3c615464bd5a92dff642dca0a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/37 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"model/qwen2-72b\"\n",
    "\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=bnb_config,\n",
    "    local_files_only = True\n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.config.pretraining_tp = 1\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (712746375.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    .to_csv(\"train2.csv\",index = False)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# train = pd.read_csv(\"text2cypher_gpt4o.csv\")\n",
    "# train1 = train[[\"question\",\"cypher\"]][:2]\n",
    "# train1\n",
    "# .to_csv(\"train2.csv\",index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fed81a1932445149251242498229b96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ls = []\n",
    "# for i in tqdm(range(len(train))):\n",
    "#     row = train.iloc[i]\n",
    "#     prompt = {\n",
    "#         \"messages\" :[\n",
    "#             {\"role\": \"system\", \"content\": \"You are an expert knowledge graph annotator and you respond in JSON. Here's the json schema you must adhere to where each element is a new triple if needed\"},\n",
    "#             {\"role\": \"user\", \"content\": f'transfrom this to cypher {row[\"question\"]}'},\n",
    "#             {'role': 'assistant', 'content': f'{row[\"cypher\"]}'}\n",
    "#         ]\n",
    "#     }\n",
    "#     ls.append(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# with open(\"train_full.json\", \"w\") as json_file:\n",
    "#     json.dump(ls, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = load_dataset(\"json\",data_files = \"train_full.json\",split=\"train\").train_test_split(test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset[\"train\"][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a07b93591bb64ea38403cd5d70fb8324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7574 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# peft_config = LoraConfig(\n",
    "#     lora_alpha=16,\n",
    "#     r=64,\n",
    "#     bias=\"none\",\n",
    "#     task_type=\"CAUSAL_LM\",\n",
    "#     target_modules=[\"q_proj\",\n",
    "#             \"k_proj\",\n",
    "#             \"v_proj\",\n",
    "#             \"o_proj\",\n",
    "#             \"up_proj\",\n",
    "#             \"gate_proj\",\n",
    "#             \"down_proj\",]\n",
    "# )\n",
    "\n",
    "# training_arguments = TrainingArguments(\n",
    "#     output_dir=\"logs\",\n",
    "#     num_train_epochs=2,\n",
    "#     per_device_train_batch_size=1,\n",
    "#     gradient_accumulation_steps=8,\n",
    "#     gradient_checkpointing=False,\n",
    "#     optim=\"paged_adamw_32bit\",\n",
    "#     save_steps=0,\n",
    "#     logging_steps=25,\n",
    "#     learning_rate=2e-1,\n",
    "#     weight_decay=0.001,\n",
    "#     fp16=True,\n",
    "#     bf16=False,\n",
    "#     max_grad_norm=0.3,\n",
    "#     max_steps=-1,\n",
    "#     warmup_ratio=0.03,\n",
    "#     group_by_length=True,\n",
    "#     lr_scheduler_type=\"cosine\",\n",
    "#     # report_to=\"tensorboard\",\n",
    "#     do_eval=False,\n",
    "#     evaluation_strategy=\"no\",\n",
    "# )\n",
    "\n",
    "# trainer = SFTTrainer(\n",
    "#     model=model,\n",
    "#     train_dataset=train_dataset[\"train\"],\n",
    "#     peft_config=peft_config,\n",
    "#     tokenizer=tokenizer,\n",
    "#     args=training_arguments,\n",
    "#     packing=False,\n",
    "#     max_seq_length=512,\n",
    "\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [{'content': \"You are an expert knowledge graph annotator and you respond in JSON. Here's the json schema you must adhere to where each element is a new triple if needed\",\n",
       "   'role': 'system'},\n",
       "  {'content': 'transfrom this to cypher Which organizations in New York City have the most employees, list the top 3.',\n",
       "   'role': 'user'},\n",
       "  {'content': 'MATCH (o:Organization)-[:IN_CITY]->(c:City {name: \"New York City\"})\\nRETURN o.name, o.nbrEmployees\\nORDER BY o.nbrEmployees DESC\\nLIMIT 3',\n",
       "   'role': 'assistant'}]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\", model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    model_kwargs={\"torch_dtype\": torch.float16},\n",
    "    trust_remote_code = True,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "if full_transcript:\n",
    "    prompt = full_transcript\n",
    "else:\n",
    "    prompt = \"\"\"มีการรายงานข่าวเกี่ยวกับเหตุการณ์ที่เจ้าหน้าที่ตำรวจเข้าตรวจสอบอาจารย์หญิงคนหนึ่งที่เป็นผู้นำทางจิตวิญญาณของชาวบ้านในสำนักสุขาวดี จังหวัดอุดรธานี โดยตอนแรกเจ้าหน้าที่ไม่ทราบชื่อจริงของเธอ จนกระทั่งพบว่าเธอเคยเปลี่ยนชื่อมาหลายครั้ง และมีหมายจับเกี่ยวกับการทุจริตและการนำเข้าข้อมูลอันเป็นเท็จสู่ระบบคอมพิวเตอร์เมื่อเจ้าหน้าที่ควบคุมตัวอาจารย์หญิงคนนี้ เธอกล่าวว่าไม่ได้รู้สึกเครียดและบอกว่าร่างของเธอถูกครอบครองโดยวิญญาณอื่น จากการตรวจสอบพบว่าเธอเคยเป็นนักธุรกิจและซีอีโอของบริษัทหนึ่ง ซึ่งหลังจากมีคดีความเกี่ยวกับการเงิน เธอก็หันมาเป็นผู้นำทางจิตวิญญาณในห้องขัง เธอนั่งสมาธิและอ้างว่าได้ช่วยปลดปล่อยดวงวิญญาณนักรบในอดีตหลายหมื่นดวง อย่างไรก็ตาม เจ้าหน้าที่ตำรวจยืนยันว่าเธอมีคดีความที่ยังต้องสอบสวนและมีการควบคุมตัวต่อไป ซึ่งเธอได้รับการประกันตัวในที่สุดเหตุการณ์นี้ทำให้หลายคนสงสัยเกี่ยวกับความเชื่อและพฤติกรรมของเธอ รวมถึงการดำเนินการของเจ้าหน้าที่ในการตรวจสอบคดีความของเธอที่เกี่ยวข้องกับการทุจริตในอดีต\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_transcript = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool(full_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "if full_transcript:\n",
    "    prompt = full_transcript\n",
    "else:\n",
    "    prompt = \"\"\"มีการรายงานข่าวเกี่ยวกับเหตุการณ์ที่เจ้าหน้าที่ตำรวจเข้าตรวจสอบอาจารย์หญิงคนหนึ่งที่เป็นผู้นำทางจิตวิญญาณของชาวบ้านในสำนักสุขาวดี จังหวัดอุดรธานี โดยตอนแรกเจ้าหน้าที่ไม่ทราบชื่อจริงของเธอ จนกระทั่งพบว่าเธอเคยเปลี่ยนชื่อมาหลายครั้ง และมีหมายจับเกี่ยวกับการทุจริตและการนำเข้าข้อมูลอันเป็นเท็จสู่ระบบคอมพิวเตอร์เมื่อเจ้าหน้าที่ควบคุมตัวอาจารย์หญิงคนนี้ เธอกล่าวว่าไม่ได้รู้สึกเครียดและบอกว่าร่างของเธอถูกครอบครองโดยวิญญาณอื่น จากการตรวจสอบพบว่าเธอเคยเป็นนักธุรกิจและซีอีโอของบริษัทหนึ่ง ซึ่งหลังจากมีคดีความเกี่ยวกับการเงิน เธอก็หันมาเป็นผู้นำทางจิตวิญญาณในห้องขัง เธอนั่งสมาธิและอ้างว่าได้ช่วยปลดปล่อยดวงวิญญาณนักรบในอดีตหลายหมื่นดวง อย่างไรก็ตาม เจ้าหน้าที่ตำรวจยืนยันว่าเธอมีคดีความที่ยังต้องสอบสวนและมีการควบคุมตัวต่อไป ซึ่งเธอได้รับการประกันตัวในที่สุดเหตุการณ์นี้ทำให้หลายคนสงสัยเกี่ยวกับความเชื่อและพฤติกรรมของเธอ รวมถึงการดำเนินการของเจ้าหน้าที่ในการตรวจสอบคดีความของเธอที่เกี่ยวข้องกับการทุจริตในอดีต\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutting(prompt):\n",
    "    messagee = prompt.split(\" \")\n",
    "    return messagee\n",
    "messagee = cutting(prompt)\n",
    "messagee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['มีการรายงานข่าวเกี่ยวกับเหตุการณ์ที่เจ้าหน้าที่ตำรวจเข้าตรวจสอบอาจารย์หญิงคนหนึ่งที่เป็นผู้นำทางจิตวิญญาณของชาวบ้านในสำนักสุขาวดี',\n",
       " 'จังหวัดอุดรธานี',\n",
       " 'โดยตอนแรกเจ้าหน้าที่ไม่ทราบชื่อจริงของเธอ',\n",
       " 'จนกระทั่งพบว่าเธอเคยเปลี่ยนชื่อมาหลายครั้ง',\n",
       " 'และมีหมายจับเกี่ยวกับการทุจริตและการนำเข้าข้อมูลอันเป็นเท็จสู่ระบบคอมพิวเตอร์เมื่อเจ้าหน้าที่ควบคุมตัวอาจารย์หญิงคนนี้',\n",
       " 'เธอกล่าวว่าไม่ได้รู้สึกเครียดและบอกว่าร่างของเธอถูกครอบครองโดยวิญญาณอื่น',\n",
       " 'จากการตรวจสอบพบว่าเธอเคยเป็นนักธุรกิจและซีอีโอของบริษัทหนึ่ง',\n",
       " 'ซึ่งหลังจากมีคดีความเกี่ยวกับการเงิน',\n",
       " 'เธอก็หันมาเป็นผู้นำทางจิตวิญญาณในห้องขัง',\n",
       " 'เธอนั่งสมาธิและอ้างว่าได้ช่วยปลดปล่อยดวงวิญญาณนักรบในอดีตหลายหมื่นดวง',\n",
       " 'อย่างไรก็ตาม',\n",
       " 'เจ้าหน้าที่ตำรวจยืนยันว่าเธอมีคดีความที่ยังต้องสอบสวนและมีการควบคุมตัวต่อไป',\n",
       " 'ซึ่งเธอได้รับการประกันตัวในที่สุดเหตุการณ์นี้ทำให้หลายคนสงสัยเกี่ยวกับความเชื่อและพฤติกรรมของเธอ',\n",
       " 'รวมถึงการดำเนินการของเจ้าหน้าที่ในการตรวจสอบคดีความของเธอที่เกี่ยวข้องกับการทุจริตในอดีต']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persona_cypher = \"\"\"Name: Alex Cipher\n",
    "\n",
    "# Title: Data Scientist and Cypher Query Specialist\n",
    "\n",
    "# Skills:\n",
    "\n",
    "# Natural Language Processing (NLP): Proficient in transforming natural language text into structured data.\n",
    "# Graph Databases: Expert in Neo4j and other graph database technologies.\n",
    "# Cypher Query Language: Advanced knowledge and extensive experience in writing and optimizing Cypher queries.\n",
    "# Machine Learning: Familiar with machine learning techniques for text analysis and conversion.\n",
    "# Programming Languages: Skilled in Python, with specific libraries such as py2neo and networkx for interacting with graph databases.\n",
    "# Data Parsing and Transformation: Expertise in parsing text data and transforming it into query-friendly formats.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mas = []\n",
    "# for i in messagee:\n",
    "#     txt_messages = [\n",
    "#         {\"role\": \"system\", \"content\": \"\"\"You are an expert knowledge graph annotator and you respond in JSON and respond only the querry.\n",
    "#         Here's the json schema you must adhere to where each element is a new triple if needed.\n",
    "#         you must answer like this [\n",
    "#             input =  วัดเทพเจริญ เขารับร่อ\n",
    "#             output = |<start>|{\"subject\": \"วัดเทพเจริญ\", \"predicate\": \"LOCATION\", \"object\": \"เขารับร่อ\"}|<end>|\n",
    "#             input =  วัดเทพเจริญ คลองรับร่อ\n",
    "#             output = |<start>|{\"subject\": \"วัดเทพเจริญ\", \"predicate\": \"LOCATION\", \"object\": \"คลองรับร่อ\"}|<end>|\n",
    "#             input =  วัดเทพเจริญ เมืองนคร\n",
    "#             output = |<start>|{\"subject\": \"วัดเทพเจริญ\", \"predicate\": \"LOCATION\", \"object\": \"เมืองนคร\"}}|<end>|\n",
    "#             input =  วัดเทพเจริญ สมัยอยุธยา\n",
    "#             output = |<start>|{\"subject\": \"วัดเทพเจริญ\", \"predicate\": \"DATE\", \"object\": \"สมัยอยุธยา\"}|<end>|\n",
    "#             input =  วัดเทพเจริญ ถ้ำรับร่อ\n",
    "#             output = |<start>|{\"subject\": \"วัดเทพเจริญ\", \"predicate\": \"PLACE\", \"object\": \"ถ้ำรับร่อ\"|<end>|\n",
    "#             input = นายจันทร์เรียนอยู่ที่วัดเทพเจริญ ณ เวลา 15.30 น.\n",
    "#             output = |<start>|{\"subject\": \"นายจันทร์\", \"predicate\": \"STUDY\", \"object\": \"วัดเทพเจริญ\"}|<end>|,|<start>|{\"subject\": \"นายจันทร์\", \"predicate\": \"TIME\", \"object\": \"15.30 น.\"}|<end>|\n",
    "    \n",
    "#             ]\n",
    "#             if output has more than one use \",\" between them \n",
    "#         \"\"\"},\n",
    "#         {\"role\": \"user\", \"content\":f\"{i}\"}\n",
    "#     ]\n",
    "#     mas.append(txt_messages)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "persona_llm = \"\"\"you are Narin Phon an experrt in correcting sentence\n",
    "Skills:\n",
    "Text Correction: Expertise in identifying and correcting grammatical, syntactical, and contextual errors in Thai text.\n",
    "Data Annotation: Experience in creating and managing annotated datasets for training language models.\"\"\"\n",
    "massive = []\n",
    "for i in messagee:\n",
    "    txt_messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"\"\"{persona_llm}.\n",
    "        you must answer like this [\n",
    "            input =  พระบรมมทาตสวีตั้งอยู่บนถนนเพชรเกษมที่ตั้งท่ามกลางทะเลอันดาหมั่นของจังหวัดสงขลานมีตำนานเกี่ยวกับอารังกาศักดิ์สิทธิิ์ซึ่งรวมอยู่ในภูเหารับล่อใกล้เคียงขับ\n",
    "            output = |<start>|พระบรมธาตุสวีตั้งอยู่บนถนนเพชรเกษมที่ตั้งท่ามกลางทะเลอันดามันของจังหวัดสงขลา มีตำนานเกี่ยวกับลังกาศักดิ์สิทธิ์ซึ่งร่วมอยู่ในภูเขารับร่อใกล้เคียงครับ|<end>|\n",
    "            ]\n",
    "            if output has more than one use \",\" between them \n",
    "        \"\"\"},\n",
    "        {\"role\": \"user\", \"content\":f\"{i}\"}\n",
    "    ]\n",
    "    massive.append(txt_messages)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token(word):\n",
    "    \"\"\"\n",
    "    Get the token of a word using a specified tokenizer model from Hugging Face.\n",
    "\n",
    "    :param word: The word to be tokenized\n",
    "    :param model_name: The name of the pre-trained model to use for tokenization\n",
    "    :return: List of tokens\n",
    "    \"\"\"\n",
    "    # Initialize the tokenizer\n",
    "    \n",
    "    # Tokenize the word\n",
    "    tokens = tokenizer.tokenize(word)\n",
    "    \n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69b77a48ddf04a8bb313a735d48734f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "/lustrefs/disk/project/ck900819-ckos19/loader/ida-env/lib/python3.12/site-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "outputs = []\n",
    "for j in tqdm(range(len(messagee))):\n",
    "    i = messagee[j]\n",
    "    txt_messages = massive[j]\n",
    "    out = pipeline(\n",
    "        txt_messages,\n",
    "        max_new_tokens=128,\n",
    "        temperature=0.01,\n",
    "        early_stopping=True,\n",
    "        num_beams=1,top_k=3, \n",
    "        eos_token_id=model.config.eos_token_id\n",
    "    )\n",
    "    # print(out)\n",
    "    outputs.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': [{'role': 'system',\n",
       "    'content': 'you are Narin Phon an experrt in correcting sentence\\nSkills:\\nText Correction: Expertise in identifying and correcting grammatical, syntactical, and contextual errors in Thai text.\\nData Annotation: Experience in creating and managing annotated datasets for training language models..\\n        you must answer like this [\\n            input =  พระบรมมทาตสวีตั้งอยู่บนถนนเพชรเกษมที่ตั้งท่ามกลางทะเลอันดาหมั่นของจังหวัดสงขลานมีตำนานเกี่ยวกับอารังกาศักดิ์สิทธิิ์ซึ่งรวมอยู่ในภูเหารับล่อใกล้เคียงขับ\\n            output = |<start>|พระบรมธาตุสวีตั้งอยู่บนถนนเพชรเกษมที่ตั้งท่ามกลางทะเลอันดามันของจังหวัดสงขลา มีตำนานเกี่ยวกับลังกาศักดิ์สิทธิ์ซึ่งร่วมอยู่ในภูเขารับร่อใกล้เคียงครับ|<end>|\\n            ]\\n            if output has more than one use \",\" between them \\n        '},\n",
       "   {'role': 'user',\n",
       "    'content': 'รวมถึงการดำเนินการของเจ้าหน้าที่ในการตรวจสอบคดีความของเธอที่เกี่ยวข้องกับการทุจริตในอดีต'},\n",
       "   {'role': 'assistant',\n",
       "    'content': '|<start>|รวมถึงการดำเนินการของเจ้าหน้าที่ในการตรวจสอบคดีความของเธอที่เกี่ยวข้องกับการทุจริตในอดีต|<end>|'}]}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'มีการรายงานข่าวเกี่ยวกับเหตุการณ์ที่เจ้าหน้าที่ตำรวจเข้าตรวจสอบอาจารย์หญิงคนหนึ่งที่เป็นผู้นำทางจิตวิญญาณของชาวบ้านในสำนักสุขาวดีครับ จังหวัดอุดรธานี โดยตอนแรกเจ้าหน้าที่ไม่ทราบชื่อจริงของเธอ จนกระทั่งพบว่าเธอเคยเปลี่ยนชื่อมาหลายครั้งครับ และมีหมายจับเกี่ยวกับการทุจริตและการนำเข้าข้อมูลอันเป็นเท็จสู่ระบบคอมพิวเตอร์ เมื่อเจ้าหน้าที่ควบคุมตัวอาจารย์หญิงคนนี้ เธอกล่าวว่าไม่ได้รู้สึกเครียดและบอกว่าร่างของเธอถูกครอบครองโดยวิญญาณอื่น จากการตรวจสอบพบว่าเธอเคยเป็นนักธุรกิจและซีอีโอของบริษัทหนึ่ง ซึ่งหลังจากมีคดีความเกี่ยวกับการเงิน เธอก็หันมาเป็นผู้นำทางจิตวิญญาณ ในห้องขัง เธอนั่งสมาธิและอ้างว่าได้ช่วยปลดปล่อยดวงวิญญาณนักรบในอดีตหลายหมื่นดวง อย่างไรก็ตาม เจ้าหน้าที่ตำรวจยืนยันว่าเธอมีคดีความที่ยังต้องสอบสวนและมีการควบคุมตัวต่อไป ซึ่งเธอได้รับการประกันตัวในที่สุด เหตุการณ์นี้ทำให้หลายคนสงสัยเกี่ยวกับความเชื่อและพฤติกรรมของเธอ รวมถึงการดำเนินการของเจ้าหน้าที่ในการตรวจสอบคดีความของเธอที่เกี่ยวข้องกับการทุจริตในอดีต'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def extract_and_combine(text):\n",
    "    \"\"\"\n",
    "    Extract JSON strings between |<start>| and |<end>| markers and combine them into a single JSON array.\n",
    "\n",
    "    :param text: The input text containing the JSON strings\n",
    "    :return: A combined JSON string\n",
    "    \"\"\"\n",
    "    trl_ar = []\n",
    "    # Regular expression to find JSON strings between |<start>| and |<end>|\n",
    "    pattern = r'\\|<start>\\|(.*?)\\|<end>\\|'\n",
    "    matches = re.findall(pattern, text)\n",
    "    [trl_ar.append(matche) for matche in matches]\n",
    "    # # Parse the matched JSON strings and combine them into a list\n",
    "    # json_objects = [json.loads(match) for match in matches]\n",
    "    \n",
    "    # # Convert the list of JSON objects back to a JSON string\n",
    "    # combined_json_string = json.dumps(json_objects, ensure_ascii=False)\n",
    "    \n",
    "    return trl_ar\n",
    "\n",
    "# Example usage\n",
    "\n",
    "# def to_dfa(cleaned):\n",
    "#     sj = []\n",
    "#     pt = []\n",
    "#     oj = []\n",
    "#     for st in cleaned:\n",
    "#         for sub_st in st:\n",
    "#             pattern = r'\"subject\": \"(.*?)\"'\n",
    "#             subject = re.findall(pattern, sub_st)\n",
    "#             pattern = r'\"predicate\": \"(.*?)\"'\n",
    "#             predicate = re.findall(pattern, sub_st)\n",
    "#             pattern = r'\"object\": \"(.*?)\"'\n",
    "#             objecta = re.findall(pattern, sub_st)\n",
    "#             sj.append(subject[0])\n",
    "#             pt.append(predicate[0])\n",
    "#             oj.append(objecta[0])\n",
    "\n",
    "#     dicta = {\"subject\":sj,\n",
    "#         \"predicate\":pt,\n",
    "#         \"object\":oj}\n",
    "    # return pd.DataFrame(dicta)\n",
    "\n",
    "\n",
    "cleaned = []\n",
    "for i in outputs:\n",
    "    output_text = extract_and_combine(i[0][\"generated_text\"][2][\"content\"])\n",
    "    cleaned.append(output_text[0])\n",
    "# df = to_dfa(cleaned)\n",
    "# df\n",
    "correct_txt = \" \".join(cleaned)\n",
    "correct_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'มีการรายงานข่าวเกี่ยวกับเหตุการณ์ที่เจ้าหน้าที่ตำรวจเข้าตรวจสอบอาจารย์หญิงคนหนึ่งที่เป็นผู้นำทางจิตวิญญาณของชาวบ้านในสำนักสุขาวดีครับ จังหวัดอุดรธานี โดยตอนแรกเจ้าหน้าที่ไม่ทราบชื่อจริงของเธอ จนกระทั่งพบว่าเธอเคยเปลี่ยนชื่อมาหลายครั้งครับ และมีหมายจับเกี่ยวกับการทุจริตและการนำเข้าข้อมูลอันเป็นเท็จสู่ระบบคอมพิวเตอร์ เมื่อเจ้าหน้าที่ควบคุมตัวอาจารย์หญิงคนนี้ เธอกล่าวว่าไม่ได้รู้สึกเครียดและบอกว่าร่างของเธอถูกครอบครองโดยวิญญาณอื่น จากการตรวจสอบพบว่าเธอเคยเป็นนักธุรกิจและซีอีโอของบริษัทหนึ่ง ซึ่งหลังจากมีคดีความเกี่ยวกับการเงิน เธอก็หันมาเป็นผู้นำทางจิตวิญญาณ ในห้องขัง เธอนั่งสมาธิและอ้างว่าได้ช่วยปลดปล่อยดวงวิญญาณนักรบในอดีตหลายหมื่นดวง อย่างไรก็ตาม เจ้าหน้าที่ตำรวจยืนยันว่าเธอมีคดีความที่ยังต้องสอบสวนและมีการควบคุมตัวต่อไป ซึ่งเธอได้รับการประกันตัวในที่สุด เหตุการณ์นี้ทำให้หลายคนสงสัยเกี่ยวกับความเชื่อและพฤติกรรมของเธอ รวมถึงการดำเนินการของเจ้าหน้าที่ในการตรวจสอบคดีความของเธอที่เกี่ยวข้องกับการทุจริตในอดีต'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5256427,
     "sourceId": 8751275,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
